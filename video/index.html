<!doctype html><html class=no-js lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Graphics Group Videos - Michael Gleicher's Web Page</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css2?family=Bellota+Text:ital,wght@0,300;0,700;1,300&family=Libre+Baskerville&family=Poppins:wght@400;600;700&display=swap" rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=Lora&display=swap" rel=stylesheet><link rel=alternate type=application/rss+xml href=../video/index.xml title="Michael Gleicher's Web Page"><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=../css/style.css><link rel=stylesheet href=../css/559.css><link rel=stylesheet href=../css/home.css crossorigin=anonymous><link rel="shortcut icon" href=../favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=../ rel=home><img class=logo__img src=../svg/crest.svg>
</a><a class=logo__link href=../ title="Michael Gleicher's Web Page" rel=home><div class=logo__title>Michael Gleicher's Web Page</div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=../><span class=menu__text>Home</span></a></li><li class=menu__item><a class=menu__link href="https://graphics.cs.wisc.edu/Papers/?author=Gleicher"><span class=menu__text>Papers</span></a></li><li class=menu__item><a class=menu__link href=../talks><span class=menu__text>Talks</span></a></li><li class=menu__item><a class=menu__link href=../video><span class=menu__text>Videos</span></a></li><li class=menu__item><a class=menu__link href=../pages/advice><span class=menu__text>Advice</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class="main list" role=main><header class=main__header><h1 class=main__title>Graphics Group Videos</h1></header><div class=pagination><span class="pagination__item pagination__item--current">1/5</span>
<a class="pagination__item pagination__item--next btn" href=../video/page/2/>Â»</a>
<a class=inlinebtn href=../video/page/5/>(last)</a></div><article class="list__item post"><div class=video__summary style=display:flex;flex-direction:row;flex-wrap:wrap><div class=video__thumbnail style=width:200px><a href=../video/2023_rangedik/><img src=../video/2023_rangedik/rangedIK-video_hu7d4a6988fcc72d8bd1e7bc8a8de04f03_349304_180x120_fit_box_3.png alt=rangedIK-video.png></a></div><div class=video__summarybody style=width:300px;flex-grow:1><header class=list__header><h3 class="list__title post__title"><a href=../video/2023_rangedik/ rel=bookmark id=rangedik-an-optimization-based-robot-motion-generation-method-for-ranged-goal-tasks>RangedIK: An Optimization-based Robot Motion Generation Method for Ranged-Goal Tasks</a></h3><div class=video__head><div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2023-05-22T17:58:17-05:00>May, 2023</time>
<time class=meta__text datetime=2023-05-22T18:08:35-05:00>(Last Modified: May, 2023)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../categories/video/ rel=category>video</a></span></div></div><div class=video__author>By: Yeping Wang, Luis Molina, Yeping Wang, Emmanuel Senft, Bilge Mutlu, Michael Gleicher</div><div class=video__shortdesc><i>Video accompanyment for the ICRA '23 paper</i></div><p class=video__headlinks><a href="https://www.youtube.com/watch?v=-IKy0Yda8p4" class=inlinebtn>YouTube</a>&nbsp;<a href=https://graphics.cs.wisc.edu/Papers/2023/WPRG23/ class=inlinebtn>Paper Page</a>&nbsp;
<a href=https://graphics.cs.wisc.edu/GleicherAssets/Videos/2023/ICRA23_RangedIK.mp4 class=inlinebtn>mp4 file</a>&nbsp;</p></div></header><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../video/2023_rangedik/>Read formatted page...</a></span></div></div></div></article><article class="list__item post"><div class=video__summary style=display:flex;flex-direction:row;flex-wrap:wrap><div class=video__thumbnail style=width:200px><a href=../video/2022_cboxer_talk/><img src=../video/2022_cboxer_talk/mq2_hu9bd988cce3383d58f5070a204f204e1e_9098_180x120_fit_q75_box.jpg alt=mq2.jpg></a></div><div class=video__summarybody style=width:300px;flex-grow:1><header class=list__header><h3 class="list__title post__title"><a href=../video/2022_cboxer_talk/ rel=bookmark id=trinary-tools-for-continuously-valued-classifiers-cboxer-talk-video>Trinary Tools for Continuously Valued Classifiers (CBoxer Talk Video)</a></h3><div class=video__head><div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2022-03-01T00:00:00Z>March, 2022</time>
<time class=meta__text datetime=2022-06-13T20:32:07-05:00>(Last Modified: June, 2022)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../categories/video/ rel=category>video</a></span></div></div><div class=video__author>By: Michael Gleicher, Xinyi Yu, Yuheng Chen</div><div class=video__shortdesc><i>Talk Video for CBoxer (VisXAI presentation Trinary tools for continuously valued binary classifiers)</i></div><p class=video__headlinks><a href="https://www.youtube.com/watch?v=nf-8afevvdY" class=inlinebtn>YouTube</a>&nbsp;<a href=https://graphics.cs.wisc.edu/Papers/2020/GBYH20/ class=inlinebtn>Paper Page</a>&nbsp;<a href=https://pages.graphics.cs.wisc.edu/BoxerDocs/ class=inlinebtn>Project Page</a>&nbsp;
<a href=https://graphics.cs.wisc.edu/GleicherAssets/Videos/2022/pvis2022_workshop_gleicher.mp4 class=inlinebtn>mp4 file</a>&nbsp;</p></div></header><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../video/2022_cboxer_talk/>Read formatted page...</a></span></div></div></div></article><article class="list__item post"><div class=video__summary style=display:flex;flex-direction:row;flex-wrap:wrap><div class=video__thumbnail style=width:200px><a href=../video/2022_cboxer_paper/><img src=../video/2022_cboxer_paper/cboxer-title_hu800bb03104438be79c410b7bf4374daa_11806_180x120_fit_q75_box.jpg alt=cboxer-title.jpg></a></div><div class=video__summarybody style=width:300px;flex-grow:1><header class=list__header><h3 class="list__title post__title"><a href=../video/2022_cboxer_paper/ rel=bookmark id=trinary-tools-for-continuously-valued-classifiers-paper-accompaniment-video>Trinary Tools for Continuously Valued Classifiers (Paper Accompaniment Video)</a></h3><div class=video__head><div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2022-03-01T00:00:00Z>March, 2022</time>
<time class=meta__text datetime=2022-06-13T20:32:07-05:00>(Last Modified: June, 2022)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../categories/video/ rel=category>video</a></span></div></div><div class=video__author>By: Michael Gleicher, Xinyi Yu, Yuheng Chen</div><div class=video__shortdesc><i>Paper video for CBoxer</i></div><p class=video__headlinks><a href="https://www.youtube.com/watch?v=wssesx8Ezks" class=inlinebtn>YouTube</a>&nbsp;<a href=https://graphics.cs.wisc.edu/Papers/2022/GYC22/ class=inlinebtn>Paper Page</a>&nbsp;<a href=https://pages.graphics.cs.wisc.edu/BoxerDocs/ class=inlinebtn>Project Page</a>&nbsp;
<a href=https://graphics.cs.wisc.edu/GleicherAssets/Videos/2022/cboxer-vismeetsai.mp4 class=inlinebtn>mp4 file</a>&nbsp;</p></div></header><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../video/2022_cboxer_paper/>Read formatted page...</a></span></div></div></div></article><article class="list__item post"><div class=video__summary style=display:flex;flex-direction:row;flex-wrap:wrap><div class=video__thumbnail style=width:200px><a href=../video/2022_control_frames/><img src=../video/2022_control_frames/mq3_hu8c2ec96570a23477378f840cd3305d2b_9406_180x120_fit_q75_box.jpg alt=mq3.jpg></a></div><div class=video__summarybody style=width:300px;flex-grow:1><header class=list__header><h3 class="list__title post__title"><a href=../video/2022_control_frames/ rel=bookmark id=understanding-control-frames-in-multi-camera-robot-telemanipulation-talk-video>Understanding Control Frames in Multi-Camera Robot Telemanipulation (talk video)</a></h3><div class=video__head><div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2022-03-01T00:00:00Z>March, 2022</time>
<time class=meta__text datetime=2022-06-11T10:44:44-05:00>(Last Modified: June, 2022)</time></div></div><div class=video__author>By: Pragathi Praveena, Luis Molina, Yeping Wang, Emmanuel Senft, Bilge Mutlu, Michael Gleicher</div><div class=video__shortdesc><i>Video presentation for the HRI '22 paper</i></div><p class=video__headlinks><a href="https://www.youtube.com/watch?v=I70QsswkMFE" class=inlinebtn>YouTube</a>&nbsp;<a href=https://graphics.cs.wisc.edu/Papers/2022/PMWSMG22/ class=inlinebtn>Paper Page</a>&nbsp;</p></div></header><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../video/2022_control_frames/>Read formatted page...</a></span></div></div></div></article><article class="list__item post"><div class=video__summary style=display:flex;flex-direction:row;flex-wrap:wrap><div class=video__thumbnail style=width:200px><a href=../video/2021_corrections2/><img src=../video/2021_corrections2/Screenshot%202022-06-14%20160356_hu88f9918534ebae8f89080041d380a90f_769030_180x120_fit_box_3.png alt="Screenshot 2022-06-14 160356.png"></a></div><div class=video__summarybody style=width:300px;flex-grow:1><header class=list__header><h3 class="list__title post__title"><a href=../video/2021_corrections2/ rel=bookmark id=informing-real-time-corrections-in-corrective-shared-autonomy-through-expert-demonstrations>Informing Real-Time Corrections in Corrective Shared Autonomy Through Expert Demonstrations</a></h3><div class=video__head><div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2021-10-01T00:00:00Z>October, 2021</time>
<time class=meta__text datetime=2022-06-14T16:14:11-05:00>(Last Modified: June, 2022)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../categories/video/ rel=category>video</a></span></div></div><div class=video__author>By: Michael Hagenow, Emmanuel Senft, Robert Radwin, Michael Gleicher, Bilge Mutlu, Michael Zinn</div><div class=video__shortdesc><i>Video demonstrations of the corrective shared autonomy techniques focusing on approaches to learn corrective behaviors from demonstration.</i></div><p class=video__headlinks><a href="https://www.youtube.com/watch?v=48wLB2SvyiE" class=inlinebtn>YouTube</a>&nbsp;<a href=https://graphics.cs.wisc.edu/Papers/2021/HSRGMZ21a/ class=inlinebtn>Paper Page</a>&nbsp;
<a href=https://graphics.cs.wisc.edu/GleicherAssets/Videos/Hagenow/Informing_Corrections_Through_Expert_Demonstrations.mp4 class=inlinebtn>mp4 file</a>&nbsp;</p></div></header><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../video/2021_corrections2/>Read formatted page...</a></span></div></div></div></article><article class="list__item post"><div class=video__summary style=display:flex;flex-direction:row;flex-wrap:wrap><div class=video__thumbnail style=width:200px><a href=../video/2021_corrections1/><img src=../video/2021_corrections1/Screenshot%202022-06-14%20160356_hufe0fd7e03ab8bba58edb797d22c0928a_843775_180x120_fit_box_3.png alt="Screenshot 2022-06-14 160356.png"></a></div><div class=video__summarybody style=width:300px;flex-grow:1><header class=list__header><h3 class="list__title post__title"><a href=../video/2021_corrections1/ rel=bookmark id=corrective-shared-autonomy-for-addressing-task-variability>Corrective Shared Autonomy for Addressing Task Variability</a></h3><div class=video__head><div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2021-05-01T00:00:00Z>May, 2021</time>
<time class=meta__text datetime=2022-06-14T16:14:11-05:00>(Last Modified: June, 2022)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../categories/video/ rel=category>video</a></span></div></div><div class=video__author>By: Michael Hagenow, Emmanuel Senft, Robert Radwin, Michael Gleicher, Bilge Mutlu, Michael Zinn</div><div class=video__shortdesc><i>Video demonstrations of the corrective shared autonomy techniques.</i></div><p class=video__headlinks><a href="https://www.youtube.com/watch?v=-FEM8O91Xgw" class=inlinebtn>YouTube</a>&nbsp;<a href=https://graphics.cs.wisc.edu/Papers/2021/HSRGMZ21/ class=inlinebtn>Paper Page</a>&nbsp;
<a href=https://graphics.cs.wisc.edu/GleicherAssets/Videos/Hagenow/Corrective_Shared_Autonomy.mp4 class=inlinebtn>mp4 file</a>&nbsp;</p></div></header><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../video/2021_corrections1/>Read formatted page...</a></span></div></div></div></article><article class="list__item post"><div class=video__summary style=display:flex;flex-direction:row;flex-wrap:wrap><div class=video__thumbnail style=width:200px><a href=../video/2021_slip/><img src=../video/2021_slip/Screenshot%202022-06-14%20155747_huecf8f8aeeddd09c28ed749e11975bccc_934226_180x120_fit_box_3.png alt="Screenshot 2022-06-14 155747.png"></a></div><div class=video__summarybody style=width:300px;flex-grow:1><header class=list__header><h3 class="list__title post__title"><a href=../video/2021_slip/ rel=bookmark id=recognizing-orientation-slip-in-human-demonstrations>Recognizing Orientation Slip in Human Demonstrations</a></h3><div class=video__head><div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2021-05-01T00:00:00Z>May, 2021</time>
<time class=meta__text datetime=2022-06-14T16:14:11-05:00>(Last Modified: June, 2022)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../categories/video/ rel=category>video</a></span></div></div><div class=video__author>By: Michael Hagenow, Bolun Zhang, Bilge Mutlu, Michael Zinn, Michael Gleicher</div><div class=video__shortdesc><i>Video demonstrations of techniques to infer constraints and extra degrees of freedom for demonstrations where the demonstrator uses slip strategies.</i></div><p class=video__headlinks><a href="https://www.youtube.com/watch?v=9-tWTt7nt4k" class=inlinebtn>YouTube</a>&nbsp;<a href=https://graphics.cs.wisc.edu/Papers/2021/HZMZG21/ class=inlinebtn>Paper Page</a>&nbsp;
<a href=https://graphics.cs.wisc.edu/GleicherAssets/Videos/Hagenow/Recognizing_Orientation_Slip_In_Human_Demonstrations.mp4 class=inlinebtn>mp4 file</a>&nbsp;</p></div></header><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../video/2021_slip/>Read formatted page...</a></span></div></div></div></article><article class="list__item post"><div class=video__summary style=display:flex;flex-direction:row;flex-wrap:wrap><div class=video__thumbnail style=width:200px><a href=../video/2021_sprint/><img src=../video/2021_sprint/sprint_huec658481a6fe3033e20ba1fff9409610_5430_180x120_fit_q75_box.jpg alt=sprint.jpg></a></div><div class=video__summarybody style=width:300px;flex-grow:1><header class=list__header><h3 class="list__title post__title"><a href=../video/2021_sprint/ rel=bookmark id=single-query-path-planning-using-sample-efficient-probability-informed-trees>Single-query Path Planning Using Sample-efficient Probability Informed Trees</a></h3><div class=video__head><div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2021-05-01T00:00:00Z>May, 2021</time>
<time class=meta__text datetime=2022-06-11T10:44:44-05:00>(Last Modified: June, 2022)</time></div></div><div class=video__author>By: Daniel Rakita, Bilge Mutlu, Michael Gleicher</div><div class=video__shortdesc><i>This video is our virtual presentation appearing at ICRA 2021 on our path planning algorithm SPRINT (Sample-efficient PRobability INformed Trees). The paper was published as an ICRA/ RA-L paper in 2021.</i></div><p class=video__headlinks><a href="https://www.youtube.com/watch?v=I_R7CEySNJ8" class=inlinebtn>YouTube</a>&nbsp;<a href=https://graphics.cs.wisc.edu/Papers/2021/RMG21/ class=inlinebtn>Paper Page</a>&nbsp;</p></div></header><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../video/2021_sprint/>Read formatted page...</a></span></div></div></div></article><article class="list__item post"><div class=video__summary style=display:flex;flex-direction:row;flex-wrap:wrap><div class=video__thumbnail style=width:200px><a href=../video/2021_collisionik/><img src=../video/2021_collisionik/mq2_hu48c99bb47366fec4bd16e185cd8930a9_3862_180x120_fit_q75_box.jpg alt=mq2.jpg></a></div><div class=video__summarybody style=width:300px;flex-grow:1><header class=list__header><h3 class="list__title post__title"><a href=../video/2021_collisionik/ rel=bookmark id=collisionik-a-per-instant-method-for-generating-robot-motions-with-environment-collision-avoidance>CollisionIK: A Per-Instant Method for Generating Robot Motions with Environment Collision Avoidance</a></h3><div class=video__head><div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2021-03-01T00:00:00Z>March, 2021</time>
<time class=meta__text datetime=2022-06-11T10:44:44-05:00>(Last Modified: June, 2022)</time></div></div><div class=video__author>By: Daniel Rakita, Haochen Shi, Bilge Mutlu, Michael Gleicher</div><div class=video__shortdesc><i>Video acompaniment for the ICRA '21 paper</i></div><p class=video__headlinks><a href="https://www.youtube.com/watch?v=rdMl1gOPNoM" class=inlinebtn>YouTube</a>&nbsp;<a href=https://graphics.cs.wisc.edu/Papers/2021/RSMG21/ class=inlinebtn>Paper Page</a>&nbsp;</p></div></header><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../video/2021_collisionik/>Read formatted page...</a></span></div></div></div></article><article class="list__item post"><div class=video__summary style=display:flex;flex-direction:row;flex-wrap:wrap><div class=video__thumbnail style=width:200px><a href=../video/2021_strobe/><img src=../video/2021_strobe/mq3_hu4ae16a8df57cb6c47d50d8fea25a8b73_4751_180x120_fit_q75_box.jpg alt=mq3.jpg></a></div><div class=video__summarybody style=width:300px;flex-grow:1><header class=list__header><h3 class="list__title post__title"><a href=../video/2021_strobe/ rel=bookmark id=strobe-an-acceleration-meta-algorithm-for-optimizing-robot-paths-using-concurrent-interleaved-pods>Strobe: An Acceleration Meta-algorithm for Optimizing Robot Paths using Concurrent Interleaved Pods</a></h3><div class=video__head><div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2021-03-01T00:00:00Z>March, 2021</time>
<time class=meta__text datetime=2022-06-11T10:44:44-05:00>(Last Modified: June, 2022)</time></div></div><div class=video__author>By: Daniel Rakita, Bilge Mutlu, Michael Gleicher</div><div class=video__shortdesc><i>Video acompaniment for the ICRA '21 paper</i></div><p class=video__headlinks><a href="https://www.youtube.com/watch?v=WbTMh7vD3jc" class=inlinebtn>YouTube</a>&nbsp;<a href=https://graphics.cs.wisc.edu/Papers/2021/RMG21a/ class=inlinebtn>Paper Page</a>&nbsp;</p></div></header><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../video/2021_strobe/>Read formatted page...</a></span></div></div></div></article><article class="list__item post"><div class=video__summary style=display:flex;flex-direction:row;flex-wrap:wrap><div class=video__thumbnail style=width:200px><a href=../video/2020_boxer_talk/><img src=../video/2020_boxer_talk/BoxerVideo_title_huee48197f48749dd8c2ab606b7da79ec0_685570_180x120_fit_box_3.png alt=BoxerVideo_title.png></a></div><div class=video__summarybody style=width:300px;flex-grow:1><header class=list__header><h3 class="list__title post__title"><a href=../video/2020_boxer_talk/ rel=bookmark id=boxer-interactive-comparison-of-classifiers-talk-video>Boxer: Interactive Comparison of Classifiers (Talk Video)</a></h3><div class=video__head><div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2020-05-27T00:00:00Z>May, 2020</time>
<time class=meta__text datetime=2022-06-13T20:32:07-05:00>(Last Modified: June, 2022)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../categories/video/ rel=category>video</a></span></div></div><div class=video__author>By: Michael Gleicher, Aditya Barve, Xinyi Yu, and Florian Heimerl</div><div class=video__shortdesc><i>Virtual talk for EuroVis 2020 about the Boxer system for comparing machine learning classifiers.</i></div><p class=video__headlinks><a href="https://www.youtube.com/watch?v=ed1Rp-oYjy8" class=inlinebtn>YouTube</a>&nbsp;<a href=https://graphics.cs.wisc.edu/Papers/2020/GBYH20/ class=inlinebtn>Paper Page</a>&nbsp;<a href=https://pages.graphics.cs.wisc.edu/BoxerDocs/ class=inlinebtn>Project Page</a>&nbsp;
<a href=https://graphics.cs.wisc.edu/GleicherAssets/Videos/2020/2020_EV-FP-1180_v2.mp4 class=inlinebtn>mp4 file</a>&nbsp;</p></div></header><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../video/2020_boxer_talk/>Read formatted page...</a></span></div></div></div></article><article class="list__item post"><div class=video__summary style=display:flex;flex-direction:row;flex-wrap:wrap><div class=video__thumbnail style=width:200px><a href=../video/2020_boxer-demo/><img src=../video/2020_boxer-demo/system-new_hu95020f75cb2d41a6ec5f5c8d8dca80f7_477066_180x120_fit_box_3.png alt=system-new.png></a></div><div class=video__summarybody style=width:300px;flex-grow:1><header class=list__header><h3 class="list__title post__title"><a href=../video/2020_boxer-demo/ rel=bookmark id=boxer-interactive-comparison-of-classifiers-paper-video>Boxer: Interactive Comparison of Classifiers (Paper Video)</a></h3><div class=video__head><div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2020-03-01T00:00:00Z>March, 2020</time>
<time class=meta__text datetime=2020-08-02T22:03:43-05:00>(Last Modified: August, 2020)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../categories/video/ rel=category>video</a></span></div></div><div class=video__author>By: Michael Gleicher, Aditya Barve, Xinyi Yu, and Florian Heimerl</div><div class=video__shortdesc><i>Demonstration of the Boxer System from the 2020 EuroVis Paper</i></div><p class=video__headlinks><a href="https://www.youtube.com/watch?v=iSzRBLN76gc" class=inlinebtn>YouTube</a>&nbsp;<a href=https://graphics.cs.wisc.edu/Papers/2020/GBYH20/ class=inlinebtn>Paper Page</a>&nbsp;<a href=https://graphics.cs.wisc.edu/Vis/Boxer/ class=inlinebtn>Project Page</a>&nbsp;
<a href=https://graphics.cs.wisc.edu/GleicherAssets/Videos/2020/2020_boxer.mp4 class=inlinebtn>mp4 file</a>&nbsp;</p></div></header><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../video/2020_boxer-demo/>Read formatted page...</a></span></div></div></div></article><div class=pagination><span class="pagination__item pagination__item--current">1/5</span>
<a class="pagination__item pagination__item--next btn" href=../video/page/2/>Â»</a>
<a class=inlinebtn href=../video/page/5/>(last)</a></div></main></div><aside class=sidebar><div class="widget-search widget"><form class=widget-search__form role=search method=get action=../lunr-search/><label><input class=widget-search__field type=search placeholder="lunr search ..." name=q aria-label="lunr search"></label></form></div><div class="widget-links widget"><h4 class=widget__title>Sections</h4><div class="widget__content widget__list"><ul><li><a href=../>Home</a></li><li><a href="https://graphics.cs.wisc.edu/Papers/?author=Gleicher">Papers</a></li><li><a href=../talks/>Talks</a></li><li><a href=../video/>Videos</a></li><li><a href=../pages/advice/>Advice</a></li></ul></div></div><div class="widget-links widget"><h4 class=widget__title>Useful Links</h4><div class="widget__content widget__list"><ul><li><a href=https://pages.graphics.cs.wisc.edu/765-22/>CS765 Fall 2022</a></li><li><a href=https://pages.graphics.cs.wisc.edu/559-sp22/>CS559 Spring 2022</a></li><li><a href=../allpages/>List of all pages</a></li></ul></div></div><div class="widget-categories widget"><h4 class=widget__title>Categories</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=../categories/video/>video</a></li></ul></div></div></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2023 Michael Gleicher.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and a heavily hacked fork of the <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div>This page was last modified on Jul 26 2020</div></footer></div><script async defer src=../js/menu.js></script></body></html>