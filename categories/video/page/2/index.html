<!doctype html><html class=no-js lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>video - Michael Gleicher's Web Page</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css2?family=Bellota+Text:ital,wght@0,300;0,700;1,300&family=Libre+Baskerville&family=Poppins:wght@400;600;700&display=swap" rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=Lora&display=swap" rel=stylesheet><link rel=alternate type=application/rss+xml href=../../../../categories/video/index.xml title="Michael Gleicher's Web Page"><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=../../../../css/style.css><link rel=stylesheet href=../../../../css/559.css><link rel=stylesheet href=../../../../css/home.css crossorigin=anonymous><link rel="shortcut icon" href=../../../../favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=../../../../ rel=home><img class=logo__img src=../../../../svg/crest.svg>
</a><a class=logo__link href=../../../../ title="Michael Gleicher's Web Page" rel=home><div class=logo__title>Michael Gleicher's Web Page</div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=../../../../><span class=menu__text>Home</span></a></li><li class=menu__item><a class=menu__link href="https://graphics.cs.wisc.edu/Papers/?author=Gleicher"><span class=menu__text>Papers</span></a></li><li class=menu__item><a class=menu__link href=../../../../talks><span class=menu__text>Talks</span></a></li><li class=menu__item><a class=menu__link href=../../../../video><span class=menu__text>Videos</span></a></li><li class=menu__item><a class=menu__link href=../../../../pages/advice><span class=menu__text>Advice</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class="main list" role=main><header class=main__header><h1 class=main__title>video</h1></header><div class=pagination><a class=inlinebtn href=../../../../categories/video/>(first)</a>
<a class="pagination__item pagination__item--prev btn" href=../../../../categories/video/>«</a>
<span class="pagination__item pagination__item--current">2/5</span>
<a class="pagination__item pagination__item--next btn" href=../../../../categories/video/page/3/>»</a>
<a class=inlinebtn href=../../../../categories/video/page/5/>(last)</a></div><article class="list__item post"><header class=list__header><h3 class="list__title post__title" id=robust-replay-of-human-demonstrations-using-identified-constraints><a href=../../../../video/2018_robust_replay/ rel=bookmark>Robust Replay of Human Demonstrations Using Identified Constraints</a></h3><div class="list__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2018-10-01T00:00:00Z>October, 2018</time>
<time class=meta__text datetime=2022-06-14T10:58:33-05:00>(Last Modified: June, 2022)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../../../../categories/video/ rel=category>video</a></span></div></div></header><p><i>Video demonstrations of robust replay that makes use of our constraint inference techniques.</i></p><div class="content list__excerpt post__content clearfix">This video went along with a paper that was never published (it was submitted to ICRA &lsquo;19). The methods are described in Guru&rsquo;s Thesis. The constraint inference approach is discussed in this paper on Axiv.
<span class=summary__readmore><a href=../../../../video/2018_robust_replay/>Read formatted page...</a></span></div></article><article class="list__item post"><header class=list__header><h3 class="list__title post__title" id=relaxedik-real-time-synthesis-of-accurate-and-feasible-robot-arm-motion><a href=../../../../video/2018_relaxedik/ rel=bookmark>RelaxedIK: Real-time Synthesis of Accurate and Feasible Robot Arm Motion</a></h3><div class="list__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2018-06-30T00:00:00Z>June, 2018</time>
<time class=meta__text datetime=2020-08-02T22:40:08-05:00>(Last Modified: August, 2020)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../../../../categories/video/ rel=category>video</a></span></div></div></header><p><i>Video to Accompany RSS 2018 Paper</i></p><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../../../../video/2018_relaxedik/>Read formatted page...</a></span></div></article><article class="list__item post"><header class=list__header><h3 class="list__title post__title" id=an-autonomous-dynamic-camera-method-for-effective-remote-teleoperation><a href=../../../../video/2018-hri-camera/ rel=bookmark>An Autonomous Dynamic Camera Method for Effective Remote Teleoperation</a></h3><div class="list__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2018-03-01T00:00:00Z>March, 2018</time>
<time class=meta__text datetime=2020-08-02T22:40:08-05:00>(Last Modified: August, 2020)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../../../../categories/video/ rel=category>video</a></span></div></div></header><p><i>Video demonstrating our system for using a robot to operate a camera while the user interactively controls another robot. Video accompaniment to our HRI 2018 paper (best paper award winner).</i></p><div class="content list__excerpt post__content clearfix">This is the video accompaniment to our best-paper award winning paper An Autonomous Dynamic Camera Method for Effective Remote Teleoperation from HRI 2018. It demonstrates a system that allows the user to control a robot manipulator and see what they are doing by having a second robot control a video camera that watches the action.
See also the later video from the system that added more intelligence to the camera control, published at RSS 2019.
<span class=summary__readmore><a href=../../../../video/2018-hri-camera/>Read more…</a></span></div></article><article class="list__item post"><header class=list__header><h3 class="list__title post__title" id=a-motion-retargeting-method-for-effective-mimicry-based-teleoperation-of-robot-arms><a href=../../../../video/2017_mimicry/ rel=bookmark>A Motion Retargeting Method for Effective Mimicry-based Teleoperation of Robot Arms</a></h3><div class="list__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2017-03-01T00:00:00Z>March, 2017</time>
<time class=meta__text datetime=2020-08-02T22:40:08-05:00>(Last Modified: August, 2020)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../../../../categories/video/ rel=category>video</a></span></div></div></header><p><i>Video describing our system for real-time control of a robot arm, published at HRI 2017.</i></p><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../../../../video/2017_mimicry/>Read formatted page...</a></span></div></article><article class="list__item post"><header class=list__header><h3 class="list__title post__title" id=authoring-directed-gaze-for-full-body-motion-capture><a href=../../../../video/2016_gazeediting/ rel=bookmark>Authoring Directed Gaze for Full-body Motion Capture</a></h3><div class="list__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2016-12-01T00:00:00Z>December, 2016</time>
<time class=meta__text datetime=2020-08-02T22:40:08-05:00>(Last Modified: August, 2020)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../../../../categories/video/ rel=category>video</a></span></div></div></header><p><i>Video for our 2016 SIGGRAPH Asia Paper on adding and editing eye movements to motion capture data.</i></p><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../../../../video/2016_gazeediting/>Read formatted page...</a></span></div></article><article class="list__item post"><header class=list__header><h3 class="list__title post__title" id=serendip-rank-viewer><a href=../../../../video/2015_serendiprankview/ rel=bookmark>Serendip Rank Viewer</a></h3><div class="list__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2015-03-01T00:00:00Z>March, 2015</time>
<time class=meta__text datetime=2020-08-02T22:40:08-05:00>(Last Modified: August, 2020)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../../../../categories/video/ rel=category>video</a></span></div></div></header><p><i>A tutorial on using the Rank View in the Serendip Topic Model Exploration System</i></p><div class="content list__excerpt post__content clearfix">A demonstration of Serendip&rsquo;s RankViewer. Serendip is a corpus exploration tool that uses probabilistic topic modeling as a lens through which to view documents. The demonstration uses a topic model generated on a corpus of 1,080 digitized English texts published between 1530 and 1799.
<span class=summary__readmore><a href=../../../../video/2015_serendiprankview/>Read formatted page...</a></span></div></article><article class="list__item post"><header class=list__header><h3 class="list__title post__title" id=splatterplots-overcoming-overdraw-in-scatter-plots><a href=../../../../video/2013_splatterplots/ rel=bookmark>Splatterplots: Overcoming Overdraw in Scatter Plots</a></h3><div class="list__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2013-09-01T00:00:00Z>September, 2013</time>
<time class=meta__text datetime=2020-08-02T22:40:08-05:00>(Last Modified: August, 2020)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../../../../categories/video/ rel=category>video</a></span></div></div></header><p><i>Video showing the Splatterplot technique for displaying dense scatterplots. The method is described in a 2013 TVCG paper.</i></p><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../../../../video/2013_splatterplots/>Read formatted page...</a></span></div></article><article class="list__item post"><header class=list__header><h3 class="list__title post__title" id=stylized-and-performative-gaze-for-character-animation><a href=../../../../video/2013_stylizedgaze/ rel=bookmark>Stylized and Performative Gaze for Character Animation</a></h3><div class="list__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2013-05-15T00:00:00Z>May, 2013</time>
<time class=meta__text datetime=2020-08-02T22:40:08-05:00>(Last Modified: August, 2020)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../../../../categories/video/ rel=category>video</a></span></div></div></header><p><i>Video from our EuroGraphics 2013 paper on creating eye movements for cartoon characters.</i></p><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../../../../video/2013_stylizedgaze/>Read formatted page...</a></span></div></article><article class="list__item post"><header class=list__header><h3 class="list__title post__title" id=online-real-time-presentation-of-virtual-experiences-for-external-viewers><a href=../../../../video/2012_realtime_presentvr/ rel=bookmark>Online Real-Time Presentation of Virtual Experiences for External Viewers</a></h3><div class="list__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2012-10-01T00:00:00Z>October, 2012</time>
<time class=meta__text datetime=2020-08-02T22:40:08-05:00>(Last Modified: August, 2020)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../../../../categories/video/ rel=category>video</a></span></div></div></header><p><i>video accompaniment to VRST 2012 paper: Ponto, K., Shin, H. J., Kohlmann, J., & Gleicher, M. (2012). Online real-time presentation of virtual experiences forexternal viewers. In Proceedings of the 18th ACM symposium on Virtual reality software and technology - VRST ’12 (p. 45).</i></p><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../../../../video/2012_realtime_presentvr/>Read formatted page...</a></span></div></article><article class="list__item post"><header class=list__header><h3 class="list__title post__title" id=effective-replays-and-summarization-of-virtual-experiences><a href=../../../../video/2012_replayvr/ rel=bookmark>Effective Replays and Summarization of Virtual Experiences</a></h3><div class="list__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2012-04-01T00:00:00Z>April, 2012</time>
<time class=meta__text datetime=2020-08-02T22:40:08-05:00>(Last Modified: August, 2020)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../../../../categories/video/ rel=category>video</a></span></div></div></header><p><i>Video Accompaniment to: Ponto, K., Kohlmann, J., & Gleicher, M. (2012). Effective replays and summarization of virtual experiences. IEEE Transactions on Visualization and Computer Graphics, 18(4), 607–16.</i></p><div class="content list__excerpt post__content clearfix"><span class=summary__readmore><a href=../../../../video/2012_replayvr/>Read formatted page...</a></span></div></article><article class="list__item post"><header class=list__header><h3 class="list__title post__title" id=subspace-video-stabilization-tog-2011><a href=../../../../video/2011_subspacestabilization/ rel=bookmark>SubSpace Video Stabilization (ToG 2011)</a></h3><div class="list__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2011-01-01T00:00:00Z>January, 2011</time>
<time class=meta__text datetime=2020-08-02T22:40:08-05:00>(Last Modified: August, 2020)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../../../../categories/video/ rel=category>video</a></span></div></div></header><p><i>Video from our 2011 Transactions on Graphics Paper</i></p><div class="content list__excerpt post__content clearfix">Video from our 2011 Transactions on Graphics Paper.
This system provided a practical approach to warp stabilization. It is the key technical piece that lead to Adobe&rsquo;s Warp Stabilizer.
This work was done with Feng Liu, Michael Gleicher, Jue Wang, Hailin Jin, and Aseem Agarwala.
<span class=summary__readmore><a href=../../../../video/2011_subspacestabilization/>Read formatted page...</a></span></div></article><article class="list__item post"><header class=list__header><h3 class="list__title post__title" id=content-preserving-warps-for-3d-video-stabilization><a href=../../../../video/2009_warp_stable/ rel=bookmark>Content-Preserving Warps for 3D Video Stabilization</a></h3><div class="list__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2009-07-01T00:00:00Z>July, 2009</time>
<time class=meta__text datetime=2020-08-02T22:40:08-05:00>(Last Modified: August, 2020)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../../../../categories/video/ rel=category>video</a></span></div></div></header><p><i>Video demonstration of our SIGGRAPH 2009 Paper</i></p><div class="content list__excerpt post__content clearfix">This is a video demonstration from our SIGGRAPH 2009 paper &ldquo;Content-Preserving Warps for 3D Video Stabilization&rdquo;. This is an early predecessor to the technology that became Adobe&rsquo;s Warp Stabilizer (although, that is really based on a later paper).
<span class=summary__readmore><a href=../../../../video/2009_warp_stable/>Read formatted page...</a></span></div></article><div class=pagination><a class=inlinebtn href=../../../../categories/video/>(first)</a>
<a class="pagination__item pagination__item--prev btn" href=../../../../categories/video/>«</a>
<span class="pagination__item pagination__item--current">2/5</span>
<a class="pagination__item pagination__item--next btn" href=../../../../categories/video/page/3/>»</a>
<a class=inlinebtn href=../../../../categories/video/page/5/>(last)</a></div></main></div><aside class=sidebar><div class="widget-search widget"><form class=widget-search__form role=search method=get action=../../../../lunr-search/><label><input class=widget-search__field type=search placeholder="lunr search ..." name=q aria-label="lunr search"></label></form></div><div class="widget-links widget"><h4 class=widget__title>Sections</h4><div class="widget__content widget__list"><ul><li><a href=../../../../>Home</a></li><li><a href="https://graphics.cs.wisc.edu/Papers/?author=Gleicher">Papers</a></li><li><a href=../../../../talks/>Talks</a></li><li><a href=../../../../video/>Videos</a></li><li><a href=../../../../pages/advice/>Advice</a></li></ul></div></div><div class="widget-links widget"><h4 class=widget__title>Useful Links</h4><div class="widget__content widget__list"><ul><li><a href=https://pages.graphics.cs.wisc.edu/765-21/>CS765 Fall 2021</a></li><li><a href=https://graphics.cs.wisc.edu/Courses/559-sp2021/>CS559 Spring 2021</a></li><li><a href=../../../../allpages/>List of all pages</a></li></ul></div></div><div class="widget-categories widget"><h4 class=widget__title>Categories</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=../../../../categories/video/>video</a></li></ul></div></div></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2022 Michael Gleicher.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and a heavily hacked fork of the <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div>This page was last modified on Jun 14 2022</div></footer></div><script async defer src=../../../../js/menu.js></script></body></html>